#!/usr/bin/env python
# coding: utf-8
'''
## Sources 
- https://cookbook.openai.com/examples/multimodal/using_gpt4_vision_with_function_calling
- https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models
- https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models


## To-do 
Make a cycle to go over all the pictures in the folder and generate the ouput, put the numeber of the picture before the html output.
tell gabi gi make the screenshotes and numerate then by numbers

do the same for abstract 

'''
import json
import base64
import os
from io import BytesIO
import matplotlib.pyplot as plt
from PIL import Image
import openai
import tiktoken
import logging



# Function to encode the image as base64
def encode_image(image_path: str):
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"Image file not found: {image_path}")
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

# Function to resize images
def resize_image(image_path: str, max_width: int = 800):
    with Image.open(image_path) as img:
        if img.width > max_width:
            img = img.resize((max_width, int((max_width / img.width) * img.height)))
            img.save(image_path)

# Sample images for prompt
image_dir = "/Users/blagojdelipetrev/Code/EUknowledge/Numerical/prompt_images"

# Encode all images within the prompt and all_images directory 
image_files = os.listdir(image_dir)
image_data_prompt = {}
for image_file in image_files:
    image_path = os.path.join(image_dir, image_file)
    resize_image(image_path)  # Resize the image before encoding
    encoded_image = encode_image(image_path)
    image_data_prompt[image_file.split('.')[0]] = encoded_image
    logging.debug(f"Encoded image: {image_file}")

# Sample images for prompt
image_dir = "/Users/blagojdelipetrev/Code/EUknowledge/Numerical/all_images"

# Encode all images within the all_images directory 
image_files = os.listdir(image_dir)
image_data_all = {}
for image_file in image_files:
    image_path = os.path.join(image_dir, image_file)
    resize_image(image_path)  # Resize the image before encoding
    encoded_image = encode_image(image_path)
    image_data_all[image_file.split('.')[0]] = encoded_image
    logging.debug(f"Encoded image: {image_file}")



def display_images(image_data: dict):
    fig, axs = plt.subplots(1, len(image_data), figsize=(18, 6))
    for i, (key, value) in enumerate(image_data.items()):
        try:
            img = Image.open(BytesIO(base64.b64decode(value)))
            ax = axs[i]
            ax.imshow(img)
            ax.axis("off")
            ax.set_title(key)
        except Exception as e:
            logging.error(f"Error decoding image {key}: {e}")
    plt.tight_layout()
    plt.show()

display_images(image_data_all)


def display_single_image(image_data: dict, image_key: str):
    fig, ax = plt.subplots(figsize=(6, 6))
    try:
        value = image_data[image_key]
        img = Image.open(BytesIO(base64.b64decode(value)))
        ax.imshow(img)
        ax.axis("off")
        ax.set_title(image_key)
    except Exception as e:
        logging.error(f"Error decoding image {image_key}: {e}")
    plt.tight_layout()
    plt.show()

# Example usage
display_single_image(image_data_prompt, '5')

# OpenAI API setup
from openai import OpenAI

client = OpenAI(
    # defaults to os.environ.get("OPENAI_API_KEY")
    api_key=os.getenv('OPENAI_API_KEY'),
)

# Token counting function
def count_tokens(text: str, model: str = "gpt-4-turbo"):
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))

INSTRUCTION_PROMPT = 'You are a helpful assistant that solves ESPO numerical assignments. Please solve the assignment as the ones before step by step and generate HTML output.'
RESPOSE_1 = '<h1>Solution to ESPO Numerical Question</h1><ol><li>Identify the total revenue for the month: <ul><li>Total revenue: $150,000</li></ul></li><li>Determine the percentage of revenue for Fiction and Science Fiction: <ul><li>Fiction: 35%</li><li>Science Fiction: 10%</li></ul></li><li>Calculate the revenue generated by Fiction: <ul><li>Revenue from Fiction = $150,000 × 35% = $150,000 × 0.35 = $52,500</li></ul></li><li>Calculate the revenue generated by Science Fiction: <ul><li>Revenue from Science Fiction = $150,000 × 10% = $150,000 × 0.10 = $15,000</li></ul></li><li>Calculate the difference in revenue between Fiction and Science Fiction: <ul><li>Difference in revenue = $52,500 - $15,000 = $37,500</li></ul></li></ol><h2>Conclusion</h2><p>Fiction generated <strong>$37,500</strong> more in revenue compared to Science Fiction.</p>'
RESPOSE_2 = '<h1>Solution to ESPO Numerical Question</h1><ol><li>Identify the total usage hours for the month: <ul><li>Total usage hours: 10,000</li></ul></li><li>Determine the usage hours for Technology and Finance: <ul><li>Technology: 25%</li><li>Finance: 20%</li></ul></li><li>Calculate the usage hours for Technology: <ul><li>Usage hours for Technology = 10,000 × 25% = 10,000 × 0.25 = 2,500 hours</li></ul></li><li>Calculate the usage hours for Finance: <ul><li>Usage hours for Finance = 10,000 × 20% = 10,000 × 0.20 = 2,000 hours</li></ul></li><li>Calculate the combined usage hours for Technology and Finance: <ul><li>Combined usage hours = 2,500 + 2,000 = 4,500 hours</li></ul></li></ol><h2>Conclusion</h2><p>The total usage in hours for the Technology and Finance industries combined is <strong>4,500 hours</strong>.</p>'
MODEL = "gpt-4-turbo-2024-04-09"

def process_all_images(image_data_prompt: dict, image_data_all: dict):
    results = {}
    for image_key, encoded_image in image_data_all.items():
        image_url1 = f"data:image/jpeg;base64,{image_data_prompt['3']}"
        image_url2 = f"data:image/jpeg;base64,{image_data_prompt['4']}"
        image_url = f"data:image/jpeg;base64,{encoded_image}"
        messages = [
            {"role": "system", "content": INSTRUCTION_PROMPT},
            {"role": "user", "content": [{"type": "image_url", "image_url": {"url": image_url1}}]},
            {"role": "assistant", "content": RESPOSE_1},
            {"role": "user", "content": [{"type": "image_url", "image_url": {"url": image_url2}}]},
            {"role": "assistant", "content": RESPOSE_2},
            {"role": "user", "content": [{"type": "image_url", "image_url": {"url": image_url}}]},
        ]
        payload = {
            "model": MODEL,
            "messages": messages,
            "temperature": 0.0,  # for less diversity in responses
        }

        # Count tokens
        total_tokens = sum(count_tokens(json.dumps(msg), MODEL) for msg in messages)
        print(f"Total tokens used in the request: {total_tokens}")

        try:
            response = client.chat.completions.create(**payload)
            results[image_key] = response.choices[0].message.content
            print(response.choices[0].message.content)
        except Exception as e:
            logging.error(f"Error processing image {image_key}: {e}")

         # Save results to JSON file
    with open('output_results.json', 'w') as json_file:
        json.dump(results, json_file, indent=4)


# Example usage
# display_single_image(image_data, '3')  # Display a single image
# Example usage
process_all_images(image_data_prompt, image_data_all)

